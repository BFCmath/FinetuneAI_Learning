{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Tensorflow to finetune for computer vision tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Dataset Folder Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "dataset/\n",
    "├── class_1/\n",
    "│   ├── image1.jpg\n",
    "│   ├── image2.jpg\n",
    "│   └── ...\n",
    "├── class_2/\n",
    "│   ├── image1.jpg\n",
    "│   ├── image2.jpg\n",
    "│   └── ...\n",
    "└── class_n/\n",
    "    ├── image1.jpg\n",
    "    ├── image2.jpg\n",
    "    └── ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "image_size = (224, 224)  \n",
    "batch_size = 32          \n",
    "validation_split = 0.2   \n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'dataset',                  # Path to the dataset folder\n",
    "    validation_split=validation_split,\n",
    "    subset=\"training\",          # Training subset\n",
    "    seed=123,                   # Set a random seed for reproducibility\n",
    "    image_size=image_size,      \n",
    "    batch_size=batch_size       \n",
    ")\n",
    "\n",
    "# Load validation data\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'dataset',                  # Path to the dataset folder\n",
    "    validation_split=validation_split,\n",
    "    subset=\"validation\",        # Validation subset\n",
    "    seed=123,                   # Must be the same seed as above\n",
    "    image_size=image_size,      \n",
    "    batch_size=batch_size       \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "\n",
    "# Load the base model\n",
    "base_model = ResNet50(\n",
    "    weights='imagenet',          # Load weights pre-trained on ImageNet\n",
    "    include_top=False,           # Exclude the fully connected layers\n",
    "    input_shape=(224, 224, 3)    # Input size for the model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freeze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False # Freeze the base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True  # Unfreeze the base model\n",
    "\n",
    "# Optionally, freeze some layers to fine-tune specific parts\n",
    "for layer in base_model.layers[:100]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "\n",
    "# Add custom layers\n",
    "model = models.Sequential([\n",
    "    base_model,                             # Pre-trained base\n",
    "    layers.GlobalAveragePooling2D(),       # Pooling layer to reduce dimensions\n",
    "    layers.Dense(128, activation='relu'),  # Fully connected layer\n",
    "    layers.Dropout(0.5),                   # Dropout for regularization\n",
    "    layers.Dense(10, activation='softmax') # Final layer for classification\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10\n",
    ")\n",
    "model.summary() # Display the model's architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Special: Image + metadata model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.layers import Input, GlobalAveragePooling2D, Dense, Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "image_input = Input(shape=(224, 224, 3), name=\"image_input\")\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=image_input)\n",
    "base_model.trainable = False  \n",
    "\n",
    "image_features = base_model.output\n",
    "image_features = GlobalAveragePooling2D()(image_features)\n",
    "image_features = Dense(128, activation='relu')(image_features)\n",
    "image_features = Dropout(0.5)(image_features)\n",
    "\n",
    "metadata_input = Input(shape=(10,), name=\"metadata_input\")  \n",
    "metadata_features = Dense(64, activation='relu')(metadata_input)\n",
    "metadata_features = Dropout(0.3)(metadata_features)\n",
    "metadata_features = Dense(32, activation='relu')(metadata_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features = Concatenate()([image_features, metadata_features])\n",
    "\n",
    "x = Dense(128, activation='relu')(combined_features)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(10, activation='softmax', name=\"output_layer\")(x) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the multi-input model\n",
    "model = Model(inputs=[image_input, metadata_input], outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
