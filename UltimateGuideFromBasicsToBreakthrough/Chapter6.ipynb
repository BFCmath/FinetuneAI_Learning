{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Chapter 6: Stage 4: Selection of Fine-Tuning Techniques and Appropriate Model Configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "##  Steps Involved in Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "1. **Initialise the Pre-Trained Tokenizer and Model**\n",
    "2. **Modify the Model’s Output Layer**\n",
    "3. **Choose an Appropriate Fine-Tuning Strategy**: Select the fine-tuning strategy that best fits the task and the model architecture. Some Options include:\n",
    "+ Task-Specific Fine-Tuning: For tasks such as text summarisation, code generation, classification, and question answering, adapt the model using relevant datasets.\n",
    "+ Domain-Specific Fine-Tuning: Tailor the model to comprehend and generate text relevant to specific domains, such as medical, financial, or legal fields.\n",
    "+ Parameter-Efficient Fine-Tuning (PEFT): Techniques like LoRA, QLoRA, and adapters allow for fine-tuning with reduced computational costs by updating a small subset of model parameters.\n",
    "+ Half Fine-Tuning (HFT): Balance between retaining pre-trained knowledge and learning new tasks by updating only half of the model’s parameters during each fine-tuning round.\n",
    "\n",
    "4. **Set Up the Training Loop**\n",
    "5. **Incorporate Techniques for Handling Multiple Tasks**\n",
    "6. **Monitor Performance on a Validation Set**\n",
    "7. **Optimise Model Using Advanced Techniques**: Employ techniques such as Proximal Policy Optimisation (PPO) for reinforcement learning scenarios, or Direct Preference Optimisation (DPO) for aligning model outputs with human preferences. These techniques are particularly useful in fine-tuning models for tasks requiring nuanced decision-making or human-like responses.\n",
    "\n",
    "8. **Prune and optimise the Model** (if necessary)\n",
    "9. **Continuous Evaluation and Iteration**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "##  Fine-Tuning Strategies for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Task-Specific Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:400px\">\n",
    "    <img src=\"image/task_specific.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Domain-Specific Fine-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "##  Parameter-Efficient Fine-Tuning (PEFT) Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Parameter Efficient Fine Tuning (PEFT) is an impactful NLP technique that adeptly adapts pre-trained language models to various applications with remarkable efficiency. PEFT methods fine-tune only a small subset of (additional) model parameters while keeping most of the pre-trained LLM parameters frozen, thereby significantly reducing computational and storage costs. This approach mitigates the issue of catastrophic forgetting, a phenomenon where neural networks lose previously acquired knowledge and experience a significant performance decline on previously learned tasks when trained on new datasets. PEFT methods have demonstrated superior performance compared to full fine-tuning, particularly in low-data scenarios, and exhibit better generalisation to out-of-domain contexts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Adapters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Adapter-based methods introduce additional trainable parameters after the attention and fully connected\n",
    " layers of a frozen pre-trained model, aiming to reduce memory usage and accelerate training. \n",
    " \n",
    " The specific approach varies depending on the adapter; it might involve adding an extra layer or representing the\n",
    " weight updates delta as a low-rank decomposition of the weight matrix.\n",
    " \n",
    "  Regardless of the method,\n",
    " adapters are generally small yet achieve performance comparable to fully fine-tuned models, allowing for\n",
    " the training of larger models with fewer resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:600px\">\n",
    "    <img src=\"image/peft.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Low-Rank Adaptation (LoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    " Low-Rank Adaptation (LoRA) is a technique designed for fine-tuning large language models, which\n",
    " modifies the fine-tuning process by freezing the original model weights and applying changes to a separate\n",
    " set of weights, added to the original parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    " LoRA transforms the model parameters into a lower\n",
    "rank dimension, reducing the number of trainable parameters, speeding up the process, and lowering\n",
    " costs.\n",
    " \n",
    "  This method is particularly useful in scenarios where multiple clients require fine-tuned models\n",
    " for different applications, allowing for the creation of specific weights for each use case without the\n",
    " need for separate models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:500px\">\n",
    "    <img src=\"image/lora.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:300px\">\n",
    "    <img src=\"image/lora_weight.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### QLoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    " QLoRA is an extended version of LoRA designed for greater memory efficiency in large language mod\n",
    "els (LLMs) by quantising weight parameters to 4-bit precision. Typically, LLM parameters are stored\n",
    " in a 32-bit format, but QLoRA compresses them to 4-bit, significantly reducing the memory footprint.\n",
    " This allows fine-tuning on less powerful hardware, including consumer GPUs. QLoRA also quantises the\n",
    " weights of the LoRA adapters from 8-bit to 4-bit, further decreasing memory and storage requirements. Despite the reduction in bit precision, QLoRA maintains performance levels comparable\n",
    " to traditional 16-bit fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Weight-Decomposed Low-Rank Adaptation (DoRA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Weight-Decomposed Low-Rank Adaptation (DoRA) is a novel fine-tuning methodology designed to\n",
    " optimise pre-trained models by decomposing their weights into magnitude and directional components.\n",
    "\n",
    " This approach leverages the efficiency of Low-Rank Adaptation (LoRA) for directional updates, facili\n",
    "tating substantial parameter updates without altering the entire model architecture. \n",
    "\n",
    "DoRA addresses the computational challenges associated with traditional full fine-tuning (FT) by maintaining model\n",
    " simplicity and inference efficiency, while simultaneously bridging the performance gap typically observed\n",
    " between LoRA and FT. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:600px\">\n",
    "    <img src=\"image/dora.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**Comparison between LoRA and DoRA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "<div style=\"background-color:white; padding:10px; display:flex; justify-content:center;height:300px\">\n",
    "    <img src=\"image/lora_dora.png\" alt=\"\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "###  Fine-Tuning with Multiple Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
