# FinetuneAI_Learning

Hey there! ðŸ‘‹ Welcome to my little corner of GitHub where I document my journey in learning how to fine-tune AI models.

## Introduction

This repository serves as a record of my learning process and the insights I've gained while studying the fine-tuning of AI models. The aim is to create a comprehensive resource that is easy to revisit and can help others understand and implement fine-tuning techniques.

---

## Free GPU Resources

- **Platforms**:
  - [Kaggle](https://www.kaggle.com/)
  - [Google Colab](https://colab.research.google.com/)

- **Details**:
  You can explore my folders on [Kaggle](Kaggle) and [Google Colab](Colab) for in-depth guidance on using these platforms.

- **TL;DR**:
  - Kaggle and Colab provide **free GPU resources** for training AI models but within resource constraints. Efficient management is key.
  - **Recommended Use Cases**:
    - **Colab**:
      - Ideal for **small models** and quick experiments.
      - A wealth of **example usage scripts** are available.
      - Best for **debugging** and stabilizing scripts, estimating resource needs.
      - Convenient for **running inference** after fine-tuning.
      - GPU time: approximately **3 hours daily**.
    - **Kaggle**:
      - Superior for **data workflows** (faster uploads and reusing fine-tuned weights).
      - Offers **larger resources** compared to Colab.
      - Suited for **fine-tuning large models** after stabilizing scripts on Colab.
      - Excellent for **saving and sharing output files**.
      - GPU time: approximately **30 hours weekly**.
  - **Note**: Both platforms have limitations, so it's important to **manage resources efficiently**.

---

## Pretrained Models for LLM

- **Platform**: [Hugging Face](https://huggingface.co/models)
- **Details**:
  Check out my [Hugging Face](Hugging_Face) folder for detailed notes on leveraging this platform.

- **TL;DR**:
  - Hugging Face provides a **vast collection of pre-trained models** for various AI tasks.
  - The platform offers tools like the **Transformers library**, enabling seamless fine-tuning on custom datasets.
  - Many models come with ready-to-use **fine-tuning** and **inference scripts**.

---

## Fine-tuning Techniques

### Fine-tuning for LLM (Large Language Models)
For a detailed dive into my learnings, visit the [Fine-tuning on LLM](LLM) folder, where Iâ€™ve compiled notes and insights on fine-tuning large language models.

### Fine-tuning for CV (Computer Vision)
For a detailed dive into my learnings, visit the [Fine-tuning on CV](CV) folder, where Iâ€™ve compiled notes and insights on fine-tuning computer vision models.

---

## TODO

- [X] CV fine-tuning with Torch and TF.
- [ ] CV yolo fine-tuning.
- [ ] Survey on Instruction Tuning for LLM
- [ ] Blog about practical tips for Lora and QLora.
<!-- - [ ] Hugging face deep dive. -->

---

This repository will continue to grow as I learn more about fine-tuning AI models. Feel free to explore, learn, and contribute! ðŸš€
