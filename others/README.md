# LLM fine-tuning

## Introduction

This document summarizes my learnings and experiences with fine-tuning Large Language Model models. The goal is to create a concise, revisitable resource that simplifies understanding and implementation of fine-tuning techniques for LLMs.

Currently, I only summarize and note down Fine-tuning techniques for LLMs without detailed implementation.

## Papers

You can check this awesome paper/book [The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs](papers/UltimateGuideFromBasicsToBreakthrough) to get more information about fine-tuning technique.

Also check this one [Instruction Tuning Survey](papers/InstructionTuningSurvey) to understand more about Instruction Tuning.

## Blogs

+ [X] [Insight From 100 Experiments](blogs/lora/insights_100_experiments.md) - Finetuning LLMs with LoRA and QLoRA: Insights from Hundreds of Experiments
+ [ ] [Advanced Guide to training a LoRA](blogs/lora/advancd_guide_lora.md) - Essential to Advanced Guide to training a LoRA
+ [ ] [Efficient Training on a Single GPU](blogs/efficient_training_huggingface.md) - Methods and tools for efficient training on a single GPU
